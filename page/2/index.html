<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en-us">

<head>
    <title>Certum ex Incertis - Dimitri Semenovich</title>
    <meta http-equiv="content-type" content="text/html; charset=utf-8">

<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="description" content="">
<meta name="keywords" content="">
<meta name="author" content="Certum ex Incertis">
<meta name="generator" content="Hugo 0.145.0">

    

  <script type="text/x-mathjax-config">
MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [['$','$'], ['\\(','\\)']],
    displayMath: [['$$','$$'], ['\\[','\\]']],
    processEscapes: true,
    processEnvironments: true,
    menuSettings: { zoom: "Double-Click" },
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
    TeX: { equationNumbers: { autoNumber: "AMS" },
         extensions: ["AMSmath.js", "AMSsymbols.js"] }
  },
     "HTML-CSS" : {
         availableFonts : ["TeX"],
         preferredFont : "TeX",
         webFont : "TeX",
         imageFont : null
     }
 });
</script>

<script type="text/javascript"
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>







<link rel="stylesheet" href="https://yui.yahooapis.com/pure/0.6.0/pure-min.css">


    <link rel="stylesheet" href="https://yui.yahooapis.com/pure/0.6.0/grids-responsive-min.css">








<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.5.0/css/font-awesome.min.css">


<link rel="stylesheet" href="https://dvse.github.io/css/tufte.css">
<link rel="stylesheet" href="https://dvse.github.io/css/hugo-tufte.css">
<link rel="stylesheet" href="https://dvse.github.io/css/hugo-tufte-override.css">

    
<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=EB+Garamond:ital,wght@0,400..800;1,400..800&display=swap" rel="stylesheet">
</head>
<body>
    <div id="layout" class="pure-g">
        <article class="pure-u-1">
            <header class="brand">
  <h1>Certum ex Incertis</h1>
  <h2>Dimitri Semenovich</h2>
  <nav class="menu">
    <ul>
    
    
        <li><a class='' href="/">Home</a></li>
    
        <li><a class='' href="/post/">Archive</a></li>
    
        <li><a class='' href="/talks/">Talks</a></li>
    
        <li><a class='' href="/papers/">Papers</a></li>
    
        <li><a class='' href="/about/">About</a></li>
    
    </ul>
</nav>

</header>

            
            
            <section style="padding-bottom:0px;">
<h1 class="content-title" style="margin-bottom:0.5rem">
  
  <a href="/2018/data-science-10-years-on/">Data Science 10 Years On</a>
  
</h1>





<span class="content-meta">
    
    
    Dec 28, 2018&nbsp;&nbsp;
    
    
    
    <nav class="tags">
        <ul>
            
            <li><a href="https://dvse.github.io/tags/data-science">data-science</a> </li>
            
            <li><a href="https://dvse.github.io/tags/rant">rant</a> </li>
            
            <li><a href="https://dvse.github.io/tags/connections">connections</a> </li>
            
        </ul>
    </nav>
    
</span>



</section>

            <section><p><span class="newthought"> &ldquo;Data science&rdquo;, in so far as the term is still meaningful today,</span></p>
<p>roughly amounts to &ldquo;analytics at web companies&rdquo;<label for="sidenote-5c6823f153e8f186f54dd27a929c2c77-1" class="margin-toggle sidenote-number"></label>
<input type="checkbox" id="sidenote-5c6823f153e8f186f54dd27a929c2c77-1" class="margin-toggle"/>
<span class="sidenote"> And of course victims of management fads seeking to emulate said web companies. </span>
. The
particular setting of course has an impact on how the &ldquo;analytics&rdquo; are
produced and consumed (primarily manifesting as greater degree of
automation due to volumes of data and timescales to generate results).
As more and more traditional industries adopt the software centric approach, however,
only some high level patterns can be discerned.</p>
<p>Specifically, &ldquo;analytics&rdquo; is the process where some manner of systematic
measurements and observations are used as a presumably objective basis
for making decisions, delivering process improvements or optimising
(more or less abstract) performance metrics. The same theme is repeated
with variations across a wide gamut of loosely associated disciplines.
Exact definitions have proven notoriously elusive, with few convincing
distinctions from the classical notions of rational or scientific
inquiry other than through the domain of application.</p>
<p>While even a few years ago there seemed to be a a good chance that &ldquo;data science&rdquo; might become an umbrella
term<label for="sidenote-5c6823f153e8f186f54dd27a929c2c77-2" class="margin-toggle sidenote-number"></label>
<input type="checkbox" id="sidenote-5c6823f153e8f186f54dd27a929c2c77-2" class="margin-toggle"/>
<span class="sidenote"> Donoho, D. (2015). <a href="http://courses.csail.mit.edu/18.337/2015/docs/50YearsDataScience.pdf">50 Years of Data Science</a>. Tukey Centennial Workshop, Princeton </span>
for a partial rejoining of the many streams of analytics, separated
in some cases by nearly a century, it appears increasingly unlikely.
While the assessment is inherently subjective, it is difficult to detect intellectual undercurrents towards consolidation &ndash; certainly the academic world . It&rsquo;s indeed a challenge to figure out just who the intellectual &ldquo;authorities&rdquo; are. out a much stronger
intellectual undercurrent. With the large influx and no aca. Gian-Carlo Rota rather droll quip comes to mind:</p>
<blockquote>
<p><em>&ldquo;When pygmies cast such long shadows, it must be very late in the
day.&rdquo;</em></p></blockquote>
<p>What will then remain when the tide of fashion goes out? Below is a very imperfect attempt at grouping together various academic
sub-disciplines and professions (omitting actuaries) that could be
broadly said to be involved in analytics or data science and are likely to remain independent for the foreseeable future.
The association is through a subjective assessment of closeness of intellectual tradition.</p>
<p><strong>Online advertising and website optimisation</strong> &ndash; online advertising has
grown into a massive ecosystem over the last two decades providing
revenue for the majority of online services. The nature of the medium is
eminently accommodating of tracking and analytics, resulting in one of
the more dramatic applications of &ldquo;data science&rdquo;. Most sophisticated
solutions (e.g. Adwords) are deployed by inventory providers and
aggregators, such as Google and Facebook. Live A/B testing is also
prevalent among online businesses &ndash; something which is still a rarity
in traditional enterprise. This is at present the biggest area of
employment for &ldquo;data scientists&rdquo;.</p>
<p><strong>Manufacturing quality control</strong>, statistical process control, lean
manufacturing, six sigma &ndash; this is an area of analytics activity
supporting manufacturing activities and has been progressively developed
since at least 1930&rsquo;s. Among the main objectives is monitoring and
elimination of variability in manufacturing processes (e.g. part
dimensions), ensuring that defect rates are thereby controlled.</p>
<p><strong>Scientific management</strong>, management consulting, management accounting &ndash;
the broad idea of application of &ldquo;scientific&rdquo; principles to industrial
management is well over 100 years old &ndash; ubiquitous proliferation of
plans, budgets, KPIs and management reports is part of this tradition.
Very little attention is usually paid to natural statistical variation
in many metrics. Also while many controlled experimental studies have
been documented in this setting they have never become a part of the
standard methodology.</p>
<p><strong>Operations research</strong>, industrial engineering, revenue management,
mathematical optimisation, management science. Operations research began
as scientific study of military operations (e.g. convoy composition,
bomber interception protocols, logistics) during the second world war
and the principles have been exported to many other industries in the
following years. Main tools include mathematical optimisation,
stochastic processes. Mathematical optimisation is a somewhat standalone
area of research with many close connections to both computer science
and statistics.</p>
<p><strong>Statistics</strong>, - really requires no introduction, perhaps the main focus
of interest in applications has been analysis of government data, polls
and surveys and support for evaluation of experimental results in life
sciences and medicine.</p>
<p><strong>Engineering control</strong>, control theory, signal processing From
fly-by-wire systems to cellular networks and synthetic aperture radar.
Much less ambitious in scope than AI, but this systems work reliably and
are by now absolutely ubiquitous.</p>
<p><strong>Econometrics</strong>, mechanism design, causal inference (from observational
data) &ndash; due to the difficulty and costs of real world experiments in
economics, econometricians have developed tools and conceptual
frameworks for causal inference with observational data. Furthermore
mechanism design and the study of auctions have had significant impact
on the design of online marketplaces.</p>
<p><strong>Applied finance</strong>, financial engineering, algorithmic trading, HFT, risk
management. There are close parallels between data science and
quantitative finance in the 1980s and 1990s. This is not surprising,
because in market execution is a key part of any model driven trading
strategy, placing a premium on &ldquo;hacking skills&rdquo;. At present it is
perhaps reasonable to view majority of &ldquo;data scientists&rdquo; as &ldquo;quants&rdquo; of
digital advertising.</p>
<p><strong>Business intelligence</strong>, database / warehouse design, dashboards
&ndash;business intelligence is primarily IT vendor driven activity to
support management reporting in traditional enterprise with perhaps
strongest intellectual links to the academic databases research
community. Traditionally little attention has been paid to statistical
aspects of &ldquo;business intelligence&rdquo; or how it is to be actioned.</p>
<p><strong>Machine learning</strong>, natural language processing, computer vision, data
mining &ndash; machine learning is a branch of computer science that
initially focused on more tractable aspects of artificial intelligence,
primarily by constructing models from example data using statistical
methods rather than designing them by hand from general principles. Two
large application areas are computer vision and natural language
processing, including machine translation. By now the differences
between theoretical machine learning and statistics communities is
largely superficial, amounting to little more than preferences for
different styles of analysis of statistical procedures. Machine learning
research has also provided many of the tools used in analytics for
online advertising and algorithmic trading. Data mining has originated
from the databases research community and by now has mostly converged
with machine learning in terms of both objectives and methodologies.</p>
</section>
            
            <section style="padding-bottom:0px;">
<h1 class="content-title" style="margin-bottom:0.5rem">
  
  <a href="/2017/basic-theory-of-entity-resolution/">Basic Theory of Entity Resolution</a>
  
</h1>





<span class="content-meta">
    
    
    Apr 10, 2017&nbsp;&nbsp;
    
    
    
    <nav class="tags">
        <ul>
            
            <li><a href="https://dvse.github.io/tags/entity-resolution">entity-resolution</a> </li>
            
            <li><a href="https://dvse.github.io/tags/record-linkage">record-linkage</a> </li>
            
            <li><a href="https://dvse.github.io/tags/data-science">data-science</a> </li>
            
            <li><a href="https://dvse.github.io/tags/statistics">statistics</a> </li>
            
        </ul>
    </nav>
    
</span>



</section>

            <section><p>In this post I&rsquo;ll cover the classical record linkage formalism, key simplifying assumptions, and links to modern techniques.</p>
<h2 id="a-model-for-independent-decisions">A model for independent decisions</h2>
<p>Classical Fellegi-Sunter (1969) record linkage model is as follows — consider two sets of records $A$ and $B$, with elements denoted $a$ and $b$ respectively. Product set $A \times B$ is somehow partitioned into matches $M$ and non-matches $U$.</p>
<p>Pairs $(a,b)$ in $M$ typically agree on attributes such as first name, last name, components of date of birth and address. Pairs in $U$ may have isolated random agreements on some of these. The aim is then to recover $M$ while only having access to record attributes.</p>
<p>It should be noted that this set-up allows multiple matches between elements of $A$ and $B$ with uncertain interpretation. Further restrictions on the structure of $M$, however, require modifications to the basic &ldquo;theory&rdquo;.</p>
<p>We denote the vector of &ldquo;agreement codes&rdquo; as:</p>
<p>$$\gamma(a,b)=\big(\gamma_1(a,b),\gamma_2(a,b),\ldots,\gamma_n(a,b)\big)$$</p>
<p>where $\gamma_i(a,b)$ might be an indicator corresponding to statements like &ldquo;name is the same&rdquo;, &ldquo;name is the same and is Brown&rdquo;, &ldquo;name disagrees&rdquo;, &ldquo;name missing on one record&rdquo;, &ldquo;agreement on city part of address but not the street&rdquo;.</p>
<p>All possible realizations of agreement codes form the <em>comparison space</em> $\Gamma$, i.e. $\gamma(a,b) \in \Gamma$ for all $(a,b) \in A\times B$.</p>
<p>A randomized <em>decision rule</em> or <em>linkage rule</em> is then the mapping:</p>
<p>$$d\big(\gamma(a,b)\big): \Gamma \rightarrow \big\{ P \big( d_i,|,\gamma(a,b) \big) ,|, i=1,2,3 \big\}$$</p>
<p>which assigns a distribution, i.e. $\sum_{i=1}^3 P\big(d_i,|,\gamma(a,b)\big)=1$, over three possible decisions ${d_1,d_2,d_3}$ to each element of $\Gamma$.</p>
<p>Here $d_1$ denotes $(a,b) \in M$ (a <em>positive link</em>), $d_3$ denotes $(a,b) \in U$ (a <em>positive non-link</em>) and $d_2$ is a <em>possible link</em>.</p>
<p>To reiterate this is not the right formalism if we want to impose restrictions on the structure of match set $M$ (e.g. one to one), as in these cases decisions can no longer be taken for individual pairs $(a,b)$ in isolation<label for="sidenote-65eaa79f518ad6e203a341c755f13c46-2" class="margin-toggle sidenote-number"></label>
<input type="checkbox" id="sidenote-65eaa79f518ad6e203a341c755f13c46-2" class="margin-toggle"/>
<span class="sidenote">This limitation is significant in applications like identity resolution where one-to-one matching is often required.</span>
.</p>
<h2 id="constructing-the-optimal-decision-rule">Constructing the optimal decision rule</h2>
<p>To construct the &ldquo;optimal&rdquo; decision rule we define the probabilities of observing $\gamma$ for a match $(a,b)\in M$:</p>
<p>$$m\big(\gamma(a,b)\big)=P\big(\gamma(a,b),|,(a,b)\in M\big)$$</p>
<p>as well as a non-match $(a,b)\in U$:</p>
<p>$$u\big(\gamma(a,b)\big)=P\big(\gamma(a,b),|,(a,b)\in U\big)$$</p>
<p>It is a straightforward application of Neyman-Pearson theory to show that the &ldquo;optimal&rdquo; decision rule with respect to the usual objectives:</p>
<p>$$P(d_1,|,U)=\sum_{(a,b)\in A\times B} u\big(\gamma(a,b)\big)P(d_1 ,|,\gamma(a,b)\big) \text{ and}$$</p>
<p>$$P(d_3,|,M)=\sum_{(a,b)\in A\times B} m\big(\gamma(a,b)\big)P(d_3 ,|,\gamma(a,b)\big)$$</p>
<p>namely one that generates fewest expected false matches for a given expected number of undetected matches (as we are dealing with a bivariate objective), is a function of the likelihood ratio $\frac{m(\gamma)}{u(\gamma)}$:</p>
<p>$$d \big(\gamma(a,b)\big)= \left\{
\begin{array}{ll}
(1,0,0),&amp;\frac{m(\gamma)}{u(\gamma)}\ge T_1\\
(0,1,0),&amp;T_2 &lt; \frac{m(\gamma)}{u(\gamma)} &lt; T_1\\
(0,0,1),&amp;\frac{m(\gamma)}{u(\gamma)}\le T_2
\end{array}\right.
$$</p>
<p>This is almost entirely unhelpful as we don&rsquo;t know probabilities $m$ or $u$. The original proposal of Newcombe et al. (1959) was to make some heroic independence assumptions<label for="sidenote-65eaa79f518ad6e203a341c755f13c46-8" class="margin-toggle sidenote-number"></label>
<input type="checkbox" id="sidenote-65eaa79f518ad6e203a341c755f13c46-8" class="margin-toggle"/>
<span class="sidenote">The independence assumption dramatically simplifies calculation but ignores correlations between attributes that often exist in real data.</span>
about the structure of $P\big(\gamma(a,b),|,(a,b)\in M\big)$:</p>
<p>$$m\big(\gamma(a,b)\big)=\prod_{i=1}^n P\big(\gamma_i(a,b),|,(a,b)\in M\big)$$</p>
<p>where $\gamma_i(a,b)$ are individual components of the agreement vector and similarly for $u(\gamma)$.</p>
<p>Notice that the log likelihood ratio can then be written as:</p>
<p>$$\log\left(\frac{m(\gamma)}{u(\gamma)}\right) = \sum_{i=1}^n\log\big(m_i(\gamma_i(a,b))\big)-\sum_{i=1}^n\log\big(u_i(\gamma_i(a,b))\big)$$</p>
<p>With some additional hand waving, you can convince yourself that if $\gamma_i$ is the simple agreement indicator for a certain binary attribute $\xi$, such as the presence of particular surname or a given month of birth:</p>
<p>$$\gamma_i(a,b)= \left\{
\begin{array}{ll}
1,&amp;\text{if } \xi(a)=1 \text{ and } \xi(b)=1,\\
0,&amp;\text{otherwise}
\end{array}\right.
$$</p>
<p>it might be reasonable to expect that when $\gamma_i\big((a,b)\big)=1$:</p>
<p>$$\log\big(m_i(1)\big)-\log\big(u_i(1)\big)\approx \log \big(\pi_\xi \big) - \log \big(\pi_\xi^2\big) = -\log\big(\pi_\xi\big)$$</p>
<p>where $\pi_\xi$ is the proportion of the combined population where the attribute is present. This gives us an intuitive scheme to assign weights to different matches, where e.g. rare names would be considered more informative than common ones.</p>
<h2 id="date-of-birth-distribution-patterns">Date of birth distribution patterns</h2>
<p>Here is an example what this might mean in a real world dataset:</p>



  
    <figure  class="class param">
  



  <label for="" class="margin-toggle">⊕</label>
  <input type="checkbox" id="" class="margin-toggle">
  <span class="marginnote">
  

  
  Date of birth frequencies showing lower birth rates on weekends and special dates. Notice particularly how weekends (especially Sundays) consistently show lower birth frequencies, demonstrating non-random patterns in date distributions that record linkage algorithms must account for.
  
  
  

  </span>


  
  <img src="/img/fellegi_sunter/age_distribution.png" alt="Date of birth log frequencies by day of the week">
  



</figure>

<h2 id="connection-to-modern-methods">Connection to modern methods</h2>
<p>Observe that the likelihood ratio can be approximated <em>directly</em>, i.e.:</p>
<p>$$\frac{m(\gamma)}{u(\gamma)} \approx \frac{P\big((a,b)\in M,|,\gamma\big)}{P\big((a,b)\in U,|,\gamma\big)}\frac{|U|}{|M|}$$</p>
<p>where the two components are estimated directly via probabilistic classifiers. Obvious downside of this is the hard requirement for &ldquo;training data&rdquo;.</p>
</section>
            
            <section style="padding-bottom:0px;">
<h1 class="content-title" style="margin-bottom:0.5rem">
  
  <a href="/2016/blockchain-and-smart-contracts-in-insurance/">Blockchain and Smart Contracts in Insurance</a>
  
</h1>





<span class="content-meta">
    
    
    Dec 31, 2016&nbsp;&nbsp;
    
    
    
    <nav class="tags">
        <ul>
            
            <li><a href="https://dvse.github.io/tags/blockchain">blockchain</a> </li>
            
            <li><a href="https://dvse.github.io/tags/smart-contracts">smart-contracts</a> </li>
            
            <li><a href="https://dvse.github.io/tags/insurance">insurance</a> </li>
            
        </ul>
    </nav>
    
</span>



</section>

            <section><p><span class="newthought"> White papers talk about </span>
&ldquo;automated audit&rdquo;, &ldquo;unprecedented financial services innovation&rdquo;,  &ldquo;sales disruption&rdquo; and the like, enabled by &ldquo;the blockchain&rdquo; &mdash; claims that are sure to leave a jaded practitioner skeptical.</p>
<p>Public blockchain technology actually consists of three relatively independent components:</p>
<ul>
<li>direct application of public key cryptography and related ideas to the facilitation of financial transaction,</li>
<li>a significant innovation in distributed consensus algorithms,</li>
<li>smart contracts.</li>
</ul>
<h2 id="cryptographic-hash-functions">Cryptographic hash functions</h2>
<p>The basic primitives underlying blockchain system, <em>cryptographic hash functions</em>, accept a string of characters of any length and return a fixed length output, e.g. $16$ bytes, while satisfying some additional properties:</p>
<p><strong>Collision resistance</strong> means that it is difficult to find two such distinct values $x$ and $y$ that cause a &ldquo;collision&rdquo;, namely that $H(x)=H(y)$. While very many such pairs exist (by Dirichlet&rsquo;s principle), finding a collision for a given $x$ should be computationally infeasible.</p>
<p><strong>Hiding</strong> property means that given the output $v$ of a hash function $v=H(r+x)$ it is impossible to discover what the input $x$ was, where $+$ denotes concatenation and $r \in$ $R$ is drawn uniformly at random from a sufficiently large set $R$.</p>
<h2 id="blockchain-data-structure">Blockchain data structure</h2>
<p>Cryptographic hash functions can be used to generate &ldquo;digests&rdquo; of arbitrary information, protecting the data against tampering &mdash; once the hash value of a file is computed, all one needs is this hash to verify the authenticity of the original file.</p>
<p>A series of files or data blocks where each block contains data as well as a hash of the previous block is called a <em>blockchain</em>.</p>
<p>This structure prevents tampering with any of the blocks as long as we know the hash of the latest block and new blocks can be added as required. Bitcoin uses blockchain to store its transaction history.</p>
<h2 id="digital-signatures">Digital signatures</h2>
<p>This is another essential component of public blockchain technology.</p>
<p>The party that intends to digitally sign messages must generate a pair of values $(s, p)$ jointly satisfying certain properties. Here $s$ is the <em>secret key</em> that needs to be kept private and $p$ is the <em>public key</em> made known.</p>
<ul>
<li>$v = \operatorname{sign}(s, m)$ &mdash; signing function takes a message $m$ and a secret key $s$ and returns signature $v$.</li>
<li>$\operatorname{validate}(p, m, v)$ &mdash; validation function takes a public key $p$, a message $m$, and a signature $v$ and evaluates to true if and only if the signature was indeed generated on the same message using the matching secret key.</li>
</ul>
<p>These functions then satisfy the condition:
\[
\operatorname{validate}\big(p, m, \operatorname{sign}(s, m)\big) = \operatorname{true}.<br>
\]</p>
<p>Final requirement is that it is not computationally feasible to fake signatures.</p>
<p>Public keys can be used to <em>identify</em> a person &mdash; in order for someone to speak for that identity they must have access to the corresponding secret key. Identity creation in this situation is completely decentralized, anyone can create $(s, p)$ pairs at any time without notification.</p>
<p>In Bitcoin and other similar system, public keys are used as payment <em>addresses</em> or account numbers.</p>
<h2 id="cryptocurrency">Cryptocurrency</h2>
<p>Let&rsquo;s consider how to implement a simple payment system using the ideas so far.</p>
<p>We will need two types of transactions &mdash; one to <em>create</em> new &ldquo;coins&rdquo; by fiat and another to <em>pay</em> coins from an existing owner to a new owner. Transactions will be recorded in a blockchain data structure.</p>
<p>Only the scheme operator is authorized to <em>create</em> new coins. To do so, they sign a transaction containing coin id, its value and public key to which the coin is assigned.</p>
<p>Anyone who owns any coins is authorized to <em>pay</em> their coins to someone else. This transaction &ldquo;deletes&rdquo; some coins and creates new coins of the same total value assigned to a new set of public keys. The transaction is signed by the owner of the coins spent.</p>
<p>Scheme operator recognizes the payment transaction as valid and appends it to the &ldquo;blockchain&rdquo; if the following conditions are satisfied:</p>
<ul>
<li>the deleted coins are active &mdash; they were created in a previous transaction and not already deleted,</li>
<li>the value of the coins deleted equals to the value of coins created,</li>
<li>the transaction is signed by the secret key corresponding to the private key to which the coins were previously assigned (only the operator can create new coins by fiat).</li>
</ul>
<p>The operator then publishes and signs the new block containing the transaction. The operator is unable to fake history of transactions as it would invalidate the blockchain or make payments on behalf of those public keys where they don&rsquo;t also control the secret key.</p>
<h2 id="distributed-consensus">Distributed consensus</h2>
<p>The major breakthrough of Bitcoin was the decentralised version of the procedure described in the previous section, eliminating the single point of failure in the operator.</p>
<p>A simplified version of the Bitcoin consensus protocol for payment transactions (ignore coin creation for the moment) is as follows:</p>
<ul>
<li>new payment transactions are broadcast to all participants,</li>
<li>each participant collects new valid transactions (in the sense described earlier) into a block,</li>
<li>at regular intervals a randomly chosen participant broadcasts its block,</li>
<li>other participants accept the block only if all transactions are valid,</li>
<li>participants demonstrate that they have accepted the block by including it in their version of the blockchain (i.e. its hash will appear in the next block that they collect).</li>
</ul>
<p>This scheme eliminates the dependency on the central authority and has reasonable properties &mdash; invalid transaction blocks (e.g. someone trying to spend coins they don&rsquo;t own) get rejected by other (honest) participants, splits can be dealt with &amp;c.</p>
<p>There are still two problems &mdash; we have no way to create new coins and in practice there is no reliable way to randomly choose a participant to nominate new block or to ascertain how many participants there actually are.</p>
<h2 id="proof-of-work">Proof of work</h2>
<p>Bitcoin offered yet another ingenious solution to both of the earlier questions.</p>
<p>Instead of being chosen randomly to announce the next block, participants instead compete at solving cryptographic puzzles. This is called a <em>proof-of-work</em> scheme.</p>
<p>For a new block to be valid, it must contain a fixed length number, called <em>nonce</em>, such as that the hash of the nonce appended to the rest of the block falls below certain target value:</p>
<p>\[
H(\operatorname{nonce} + \operatorname{new\_block}) &lt; \operatorname{target}.
\]</p>
<p>Since there is no better known strategy for finding nonces than simple enumeration, the participants win the competition essentially randomly, with the chance of winning proportional to the computational power they can bring to the problem. Competing to find nonces is also called <em>mining</em>. This approach makes it much more costly for malicious players to subvert the system.</p>
<p>Finally, to incentivize miners to solve hashing puzzles for new blocks, Bitcoin protocol allows them to include a transaction that <em>creates</em> coins of certain predefined value by fiat and assign it to the address of their choice.</p>
<h2 id="smart-contracts">Smart contracts</h2>
<p>Bitcoin does not simply store addresses of coin recipients for payment transactions but instead allows for small custom programs to be executed that check validity of a supplied public key.</p>
<p>This is a very powerful idea as it makes transactions themselves programmable. Over time it was possible to use this functionality to implement new Bitcoin applications without changing the underlying protocol. Examples include schemes that allow funds only to be claimed if $k$ out of $n$ potential beneficiaries supply their signatures, decentralised lotteries and betting.</p>
<p>More generally, these programmable transactions are known as <em>smart contracts</em>.</p>
<h2 id="applications-of-blockchain---lotteries">Applications of blockchain - lotteries</h2>
<p>A lottery is not dissimilar to an insurance pool &mdash; a large number of people deposit their money with a single counterparty who then disburses most of the money collected to a few randomly chosen individuals (after taking an often substantial fee).</p>
<p>Bitcoin and similar public blockchain systems offer a fascinating way to implement reliable distributed lotteries without a trusted central party (and potentially at much lower cost).</p>
<p>Let&rsquo;s say we have only $3$ participants, called $A$, $B$ and $C$. They send money to a specially crafted Bitcoin script which then pays out the total contribution back to one of them at random. The algorithm is as follows:</p>
<ul>
<li>Each participant picks a number &mdash; $A$ chooses $x$, $B$ chooses $y$ and $C$ chooses $z$. They then communicate $H(x)$, $H(y)$ and $H(z)$ together with their payment.</li>
<li>$A$, $B$ and $C$ create a new transaction now incorporating $x$, $y$, and $z$. The payment is made to the $(x + y + z)\ % \ 3$ participant.</li>
</ul>
<p>This scheme has certain undesirable properties but rectifying them is quite involved. Much more realistic proposals already exist and it is likely we will see fully featured distributed cryptocurrency based lotteries before long.</p>
<h2 id="applications-of-blockchain---prediction-markets">Applications of blockchain - prediction markets</h2>
<p>Another significant area of interest are so called <em>prediction</em> or <em>betting markets</em>. These offer a way for people to place bets on outcomes of a diverse range of events, from sports to elections and corporate financial results. Prediction markets are also favoured by economists as a mechanism to efficiently aggregate information from multiple sources.</p>
<p>Main components of a prediction market are as follows:</p>
<ul>
<li>A mechanism to accept funds into <em>escrow</em> and make payouts according to event outcome. This broadly corresponds to payment processing and treasury or capital management function of an insurance company.</li>
<li>An <em>arbitration process</em> for determining the outcomes in question. Arbitration can be both decentralized (by consensus of market participants, another group such miners or even another market) and centralized, provided by a trusted third party (any signed data feed can ultimately be used). Further questions arise when the outcomes are ambiguous or not a matter of public record. In insurance context this would correspond to claims assessment.</li>
<li>An <em>order book</em> or similar mechanism (such as a market maker relying on a <em>scoring rule</em>) for participants to find counterparties to trade with. An order book contains <em>bids</em> and <em>asks</em>. A bid is a buy order and ask is a sell order. Typically the ask price is higher than the bid, otherwise two participants are matched up and a trade occurs, eliminating one of the orders. This has no close analogue in insurance outside of risk securitasion.</li>
</ul>
<p>Following is an example of how a very simple bet can be implemented using the Bitcoin protocol:</p>
<ul>
<li>An arbitrator creates two pairs of keys $(s_0, p_0)$ and $(s_1, p_1)$ for &ldquo;No&rdquo; and &ldquo;Yes&rdquo; outcomes of a certain event and publishes the public keys. Once the outcome is known, they also publish the corresponding secret key.</li>
<li>$A$ wishes to bet on a &ldquo;Yes&rdquo; outcome and $B$ on a &ldquo;No&rdquo; outcome. They deposit money to a bitcoin script from which payments can be withdrawn either using signatures from $A$ and &ldquo;Yes&rdquo; or $B$ and &ldquo;No&rdquo;.</li>
</ul>
<h2 id="potential-insurance-use-cases">Potential insurance use cases</h2>
<p><strong>Digital certificates of insurance</strong> &mdash; using digital signatures on certificates of insurance to allow decentralised verification.</p>
<p><strong>Insurance pools</strong> &mdash; these are very similar to decentralised lotteries just with a different set of rules to determine the beneficiaries, arbitration can be implemented either through vote of participants or a trusted third party.</p>
<p><strong>Insurance markets</strong> &mdash; essentially the same as prediction markets (may need &ldquo;insurable interest&rdquo; constraints), insurance linked securities with parametric triggers already come very close.</p>
<p><strong>Core systems for smart contracts</strong> &mdash; internal systems implementing a centralised version of blockchain can allow rapid innovation in product design.</p>
<p>Many insurance use cases do not necessarily require full public blockchain. Early successes will likely be those that can leverage work in lotteries and prediction markets. Low friction automated outcome arbitration appears to be the key.</p>
</section>
            
            


<nav class="menu" style="margin-top:5rem">
    <ul style="display: flex;
               align-items: stretch;
               justify-content: space-between;">
    
        <li>
            <a href="/">&larr; Newer Posts</a>  

    </li>
    
    <li>
        <a href="/page/3/">Older Posts &rarr;</a>
    </li>
    
</ul>
</nav>


            <footer class="page-footer">
		<hr>
		<ul class="page-footer-menu">
		
		</ul>

  

	<div class="copyright">
	<p>
    
      &copy; 2025
    Dimitri Semenovich.
    All rights reserved.
    
  </p>
</div>
</footer>



        </article>
    </div>
</body>
</html>
